{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = 'alexnet'\n",
    "batch_size = 1\n",
    "iterations = 10\n",
    "\n",
    "net = torchvision.models.alexnet()\n",
    "is_gpu_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: GPU is available, hence switching to gpu computation.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print (\"INFO: GPU is available, hence switching to gpu computation.\")\n",
    "    is_gpu_available = True\n",
    "else:\n",
    "    print (\"INFO: GPU is not available, using CPU..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = torch.randn(batch_size, 3, 224, 224)\n",
    "if is_gpu_available:\n",
    "    inp = inp.cuda()\n",
    "    net = net.cuda()\n",
    "    \n",
    "target = torch.arange(batch_size)\n",
    "if is_gpu_available:\n",
    "    target = target.to('cuda:0')\n",
    "    \n",
    "param_copy = net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('features', Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU(inplace)\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace)\n",
      "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")), ('classifier', Sequential(\n",
      "  (0): Dropout(p=0.5)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Dropout(p=0.5)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "))])\n"
     ]
    }
   ],
   "source": [
    "sub_modules = net.__dict__['_modules']\n",
    "print (sub_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "def getLayers(module, layer_info):\n",
    "    sub_modules = module.__dict__['_modules']\n",
    "    count = 0\n",
    "    for name, sub_module in sub_modules.items():\n",
    "        if sub_module is None or isinstance(sub_module, nn.Module) is False:\n",
    "            break\n",
    "        if isinstance(sub_module, nn.Container) or isinstance(sub_module, nn.Sequential):\n",
    "            getLayers(sub_module, layer_info)\n",
    "        else:\n",
    "            layer_info.append(sub_module)\n",
    "            print (sub_module.__class__)\n",
    "\n",
    "layer_info = []\n",
    "getLayers(net, layer_info)\n",
    "print (len(layer_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    layer = layer_info[0]\n",
    "    print(layer.__class__)\n",
    "    x = torch.randn(1, 3, 224, 224).to('cuda:0')\n",
    "    print(layer)\n",
    "    output = layer(x)\n",
    "    output_size = output.size()\n",
    "    grad_output = torch.randn(output_size[0], output_size[1], output_size[2], output_size[3]).cuda()\n",
    "    output.backward(grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_time(layer, x, iter=10):\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    for j in range(1):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            print (\"Linear layer detected... \")\n",
    "        output = layer(x)\n",
    "        output_size = output.size()\n",
    "        #grad_output = torch.randn(output_size[0], output_size[1], output_size[2], output_size[3]).cuda()\n",
    "        #output.backward(grad_output)\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print (\"Elapsed time is : {}\".format(elapsed_time))\n",
    "    return elapsed_time, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Layer Num 0 --------------------------------\n",
      "Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "Elapsed time is : 0.0009970664978027344\n",
      "torch.Size([1, 64, 55, 55])\n",
      "torch.Size([1, 64, 55, 55])\n",
      "------------------------ Layer Num 1 --------------------------------\n",
      "ReLU(inplace)\n",
      "Elapsed time is : 0.0009984970092773438\n",
      "torch.Size([1, 64, 55, 55])\n",
      "torch.Size([1, 64, 55, 55])\n",
      "------------------------ Layer Num 2 --------------------------------\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Elapsed time is : 0.0\n",
      "torch.Size([1, 64, 27, 27])\n",
      "torch.Size([1, 64, 27, 27])\n",
      "------------------------ Layer Num 3 --------------------------------\n",
      "Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Elapsed time is : 0.002028226852416992\n",
      "torch.Size([1, 192, 27, 27])\n",
      "torch.Size([1, 192, 27, 27])\n",
      "------------------------ Layer Num 4 --------------------------------\n",
      "ReLU(inplace)\n",
      "Elapsed time is : 0.0\n",
      "torch.Size([1, 192, 27, 27])\n",
      "torch.Size([1, 192, 27, 27])\n",
      "------------------------ Layer Num 5 --------------------------------\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Elapsed time is : 0.0009987354278564453\n",
      "torch.Size([1, 192, 13, 13])\n",
      "torch.Size([1, 192, 13, 13])\n",
      "------------------------ Layer Num 6 --------------------------------\n",
      "Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Elapsed time is : 0.001992940902709961\n",
      "torch.Size([1, 384, 13, 13])\n",
      "torch.Size([1, 384, 13, 13])\n",
      "------------------------ Layer Num 7 --------------------------------\n",
      "ReLU(inplace)\n",
      "Elapsed time is : 0.0\n",
      "torch.Size([1, 384, 13, 13])\n",
      "torch.Size([1, 384, 13, 13])\n",
      "------------------------ Layer Num 8 --------------------------------\n",
      "Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Elapsed time is : 0.00299072265625\n",
      "torch.Size([1, 256, 13, 13])\n",
      "torch.Size([1, 256, 13, 13])\n",
      "------------------------ Layer Num 9 --------------------------------\n",
      "ReLU(inplace)\n",
      "Elapsed time is : 0.0\n",
      "torch.Size([1, 256, 13, 13])\n",
      "torch.Size([1, 256, 13, 13])\n",
      "------------------------ Layer Num 10 --------------------------------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Elapsed time is : 0.0009982585906982422\n",
      "torch.Size([1, 256, 13, 13])\n",
      "torch.Size([1, 256, 13, 13])\n",
      "------------------------ Layer Num 11 --------------------------------\n",
      "ReLU(inplace)\n",
      "Elapsed time is : 0.0\n",
      "torch.Size([1, 256, 13, 13])\n",
      "torch.Size([1, 256, 13, 13])\n",
      "------------------------ Layer Num 12 --------------------------------\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Elapsed time is : 0.0\n",
      "torch.Size([1, 256, 6, 6])\n",
      "torch.Size([1, 256, 6, 6])\n",
      "------------------------ Layer Num 13 --------------------------------\n",
      "Dropout(p=0.5)\n",
      "Elapsed time is : 0.0009989738464355469\n",
      "torch.Size([1, 256, 6, 6])\n",
      "torch.Size([1, 9216])\n",
      "------------------------ Layer Num 14 --------------------------------\n",
      "Linear(in_features=9216, out_features=4096, bias=True)\n",
      "Linear layer detected... \n",
      "Elapsed time is : 0.011966466903686523\n",
      "torch.Size([1, 4096])\n",
      "torch.Size([1, 4096])\n",
      "------------------------ Layer Num 15 --------------------------------\n",
      "ReLU(inplace)\n",
      "Elapsed time is : 0.0\n",
      "torch.Size([1, 4096])\n",
      "torch.Size([1, 4096])\n",
      "------------------------ Layer Num 16 --------------------------------\n",
      "Dropout(p=0.5)\n",
      "Elapsed time is : 0.0009951591491699219\n",
      "torch.Size([1, 4096])\n",
      "torch.Size([1, 4096])\n",
      "------------------------ Layer Num 17 --------------------------------\n",
      "Linear(in_features=4096, out_features=4096, bias=True)\n",
      "Linear layer detected... \n",
      "Elapsed time is : 0.005984306335449219\n",
      "torch.Size([1, 4096])\n",
      "torch.Size([1, 4096])\n",
      "------------------------ Layer Num 18 --------------------------------\n",
      "ReLU(inplace)\n",
      "Elapsed time is : 0.0\n",
      "torch.Size([1, 4096])\n",
      "torch.Size([1, 4096])\n",
      "------------------------ Layer Num 19 --------------------------------\n",
      "Linear(in_features=4096, out_features=1000, bias=True)\n",
      "Linear layer detected... \n",
      "Elapsed time is : 0.0019948482513427734\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 224, 224).cuda()\n",
    "output_sizes = {}\n",
    "layer_data = {}\n",
    "net_layer_data = {}\n",
    "num_linear_layer = 0\n",
    "for i in range(len(layer_info)):\n",
    "    layer_data['layer_num'] = i\n",
    "    layer = layer_info[i]\n",
    "    if i != 0:\n",
    "        prev_layer_info = net_layer_data[i - 1]\n",
    "        prev_output_size = prev_layer_info['output_size']\n",
    "        print(prev_output_size)\n",
    "        if (len(prev_output_size) == 4):\n",
    "            x = torch.randn(output_size[0], output_size[1], output_size[2], output_size[3]).cuda()\n",
    "        elif (len(prev_output_size) == 2):\n",
    "            x = torch.randn(output_size[0], output_size[1]).cuda()\n",
    "        elif (len(prev_output_size) == 3):\n",
    "            x = torch.randn(output_size[0], output_size[1], output_size[2]).cuda()\n",
    "        if (isinstance(layer, nn.Linear) and  num_linear_layer == 0):\n",
    "            x = x.view(-1, output_size[1] * output_size[2] * output_size[3]).cuda()\n",
    "            num_linear_layer = num_linear_layer + 1\n",
    "        print(x.size())\n",
    "            \n",
    "    print (\"------------------------ Layer Num {} --------------------------------\".format(i))\n",
    "    print(layer)\n",
    "    elapsed_time, output_size = generate_time(layer, x)\n",
    "    layer_data['elapsed_time'] = elapsed_time\n",
    "    layer_data['input_size'] = x.size()\n",
    "    layer_data['output_size'] = output_size\n",
    "    net_layer_data[i] = layer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "38\n",
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Linear(in_features=25088, out_features=4096, bias=True), ReLU(inplace), Dropout(p=0.5), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace), Dropout(p=0.5), Linear(in_features=4096, out_features=1000, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "### Test with other network.\n",
    "net = torchvision.models.vgg16()\n",
    "print (net)\n",
    "layer_info = []\n",
    "getLayers(net, layer_info)\n",
    "print (len(layer_info))\n",
    "print (layer_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
